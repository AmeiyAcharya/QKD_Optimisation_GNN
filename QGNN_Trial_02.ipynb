{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install qiskit qiskit-aer torch torch_geometric networkx matplotlib scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6rMLy1lnBCQ",
        "outputId": "1793929f-2efa-4928-db7a-e7d0bd21a1ea",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-1.4.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting qiskit-aer\n",
            "  Downloading qiskit_aer-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.14.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Collecting dill>=0.3 (from qiskit)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.12.2)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.14)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.1.0)\n",
            "Downloading qiskit-1.4.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_aer-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, rustworkx, pbr, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, stevedore, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch_geometric, qiskit, nvidia-cusolver-cu12, qiskit-aer\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed dill-0.3.9 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pbr-6.1.1 qiskit-1.4.2 qiskit-aer-0.17.0 rustworkx-0.16.0 stevedore-5.4.1 symengine-0.13.0 torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GATv2Conv, TransformerConv\n",
        "from torch_geometric.utils import to_undirected, negative_sampling\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
        "from scipy.constants import h, c\n",
        "from sklearn.model_selection import KFold\n",
        "import json\n",
        "from datetime import datetime\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def bce_with_logits_loss(pos_out, neg_out):\n",
        "    \"\"\"Custom BCE loss for link prediction\"\"\"\n",
        "    pos_loss = F.binary_cross_entropy_with_logits(\n",
        "        pos_out, torch.ones_like(pos_out)\n",
        "    )\n",
        "    neg_loss = F.binary_cross_entropy_with_logits(\n",
        "        neg_out, torch.zeros_like(neg_out)\n",
        "    )\n",
        "    return pos_loss + neg_loss\n",
        "\n",
        "def to_networkx(data):\n",
        "    \"\"\"Convert PyG data to NetworkX graph\"\"\"\n",
        "    G = nx.Graph()\n",
        "    edge_index = data.edge_index.cpu().numpy()\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        G.add_edge(edge_index[0, i], edge_index[1, i])\n",
        "    return G\n",
        "\n",
        "class AdvancedQuantumChannelSimulator:\n",
        "    def __init__(self, distance, wavelength=1550e-9, fiber_loss=0.2,\n",
        "                 detector_efficiency=0.1, dark_count_rate=1e-6,\n",
        "                 atmospheric_visibility=None):\n",
        "        self.distance = distance\n",
        "        self.wavelength = wavelength\n",
        "        self.fiber_loss = fiber_loss\n",
        "        self.detector_efficiency = detector_efficiency\n",
        "        self.dark_count_rate = dark_count_rate\n",
        "        self.atmospheric_visibility = atmospheric_visibility\n",
        "        self.photon_energy = h * c / wavelength\n",
        "\n",
        "    def calculate_channel_loss(self):\n",
        "        fiber_loss_db = self.fiber_loss * self.distance\n",
        "        fiber_transmission = 10 ** (-fiber_loss_db/10)\n",
        "\n",
        "        if self.atmospheric_visibility:\n",
        "            beam_divergence = 1.22 * self.wavelength / 0.1\n",
        "            geometric_loss = (0.1 / (beam_divergence * self.distance)) ** 2\n",
        "            atmospheric_loss = np.exp(-3.91 * self.distance / self.atmospheric_visibility)\n",
        "            total_transmission = fiber_transmission * geometric_loss * atmospheric_loss\n",
        "        else:\n",
        "            total_transmission = fiber_transmission\n",
        "\n",
        "        return total_transmission\n",
        "\n",
        "    def simulate_bb84_protocol(self, num_pulses=10000, mean_photon_number=0.1):\n",
        "        channel_transmission = self.calculate_channel_loss()\n",
        "        received_photons = np.random.poisson(\n",
        "            mean_photon_number * channel_transmission * self.detector_efficiency,\n",
        "            num_pulses\n",
        "        )\n",
        "        dark_counts = np.random.poisson(self.dark_count_rate, num_pulses)\n",
        "        total_counts = received_photons + dark_counts\n",
        "        basis_matches = np.random.choice([0, 1], num_pulses, p=[0.5, 0.5])\n",
        "        qber = 0.5 * (1 - np.exp(-2 * self.distance / 100))\n",
        "        errors = np.random.choice([0, 1], num_pulses, p=[1-qber, qber])\n",
        "        matched_pulses = total_counts * basis_matches\n",
        "        raw_key_rate = np.sum(matched_pulses) / num_pulses\n",
        "        final_key_rate = raw_key_rate * (1 - 2 * h2(qber))\n",
        "\n",
        "        return {\n",
        "            'qber': qber,\n",
        "            'raw_key_rate': raw_key_rate,\n",
        "            'final_key_rate': final_key_rate,\n",
        "            'channel_loss_db': -10 * np.log10(channel_transmission),\n",
        "            'dark_count_probability': np.mean(dark_counts > 0)\n",
        "        }\n",
        "\n",
        "def h2(x):\n",
        "    \"\"\"Binary entropy function\"\"\"\n",
        "    return -x * np.log2(x) - (1-x) * np.log2(1-x) if 0 < x < 1 else 0\n",
        "\n",
        "class AdvancedQKDNetwork:\n",
        "    def __init__(self, num_nodes=50):\n",
        "        self.num_nodes = num_nodes\n",
        "        self.positions = self._generate_realistic_topology()\n",
        "\n",
        "    def _generate_realistic_topology(self):\n",
        "        centers = np.random.multivariate_normal(\n",
        "            mean=[0, 0],\n",
        "            cov=[[100, 0], [0, 100]],\n",
        "            size=3\n",
        "        )\n",
        "\n",
        "        positions = []\n",
        "        for _ in range(self.num_nodes):\n",
        "            center = centers[np.random.randint(0, 3)]\n",
        "            pos = center + np.random.multivariate_normal(\n",
        "                mean=[0, 0],\n",
        "                cov=[[10, 0], [0, 10]]\n",
        "            )\n",
        "            positions.append(pos)\n",
        "\n",
        "        return np.array(positions)\n",
        "\n",
        "    def generate_graph_data(self):\n",
        "        distances = np.zeros((self.num_nodes, self.num_nodes))\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(i + 1, self.num_nodes):\n",
        "                distances[i, j] = distances[j, i] = np.linalg.norm(\n",
        "                    self.positions[i] - self.positions[j]\n",
        "                )\n",
        "\n",
        "        edges = []\n",
        "        edge_attrs = []\n",
        "\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(i + 1, self.num_nodes):\n",
        "                if distances[i, j] < 100:\n",
        "                    simulator = AdvancedQuantumChannelSimulator(\n",
        "                        distance=distances[i, j],\n",
        "                        atmospheric_visibility=20000 if np.random.random() < 0.2 else None\n",
        "                    )\n",
        "                    results = simulator.simulate_bb84_protocol()\n",
        "\n",
        "                    if results['final_key_rate'] > 0:\n",
        "                        edges.append([i, j])\n",
        "                        edge_attrs.append([\n",
        "                            results['final_key_rate'],\n",
        "                            results['qber'],\n",
        "                            distances[i, j],\n",
        "                            results['channel_loss_db'],\n",
        "                            results['dark_count_probability']\n",
        "                        ])\n",
        "\n",
        "        edge_index = torch.tensor(edges).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attrs, dtype=torch.float)\n",
        "\n",
        "        G = nx.Graph()\n",
        "        G.add_edges_from(edges)\n",
        "\n",
        "        node_features = []\n",
        "        for i in range(self.num_nodes):\n",
        "            features = [\n",
        "                self.positions[i, 0],\n",
        "                self.positions[i, 1],\n",
        "                G.degree(i) if i in G else 0,\n",
        "                nx.betweenness_centrality(G).get(i, 0) if i in G else 0\n",
        "            ]\n",
        "            node_features.append(features)\n",
        "\n",
        "        return Data(\n",
        "            x=torch.tensor(node_features, dtype=torch.float),\n",
        "            edge_index=to_undirected(edge_index),\n",
        "            edge_attr=edge_attr,\n",
        "            pos=torch.tensor(self.positions, dtype=torch.float)\n",
        "        )\n",
        "\n",
        "class AdvancedQKDLinkPredictor(torch.nn.Module):\n",
        "    def __init__(self, in_channels, edge_attr_channels, hidden_channels=64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = TransformerConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GATv2Conv(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.edge_mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(edge_attr_channels, hidden_channels),\n",
        "            torch.nn.LayerNorm(hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels)\n",
        "        )\n",
        "\n",
        "        self.link_predictor = torch.nn.Sequential(\n",
        "            torch.nn.Linear(3 * hidden_channels, hidden_channels),\n",
        "            torch.nn.LayerNorm(hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.Linear(hidden_channels, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        # Process edge features for all edges\n",
        "        edge_features = self.edge_mlp(edge_attr)\n",
        "\n",
        "        return x, edge_features\n",
        "\n",
        "    def decode(self, z, edge_features, edge_label_index):\n",
        "        src, dst = edge_label_index\n",
        "\n",
        "        # Handle negative sampling case\n",
        "        if edge_features.size(0) != edge_label_index.size(1):\n",
        "            # For negative samples, create dummy edge features\n",
        "            edge_features = edge_features.mean(dim=0, keepdim=True).repeat(edge_label_index.size(1), 1)\n",
        "\n",
        "        node_features = torch.cat([\n",
        "            z[src],\n",
        "            z[dst],\n",
        "            edge_features\n",
        "        ], dim=-1)\n",
        "        return self.link_predictor(node_features).squeeze(-1)\n",
        "\n",
        "def train_and_evaluate(model, data, num_epochs=200, k_folds=5):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    data = data.to(device)\n",
        "\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    all_results = []\n",
        "    kf = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "    edge_index = data.edge_index.cpu().numpy()\n",
        "    edge_attr = data.edge_attr.cpu().numpy()\n",
        "    unique_edges = set()\n",
        "    edge_to_idx = {}\n",
        "\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        edge = tuple(sorted([edge_index[0, i], edge_index[1, i]]))\n",
        "        if edge not in unique_edges:\n",
        "            unique_edges.add(edge)\n",
        "            edge_to_idx[edge] = len(edge_to_idx)\n",
        "\n",
        "    unique_edges = list(unique_edges)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(unique_edges)):\n",
        "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
        "\n",
        "        train_edges = [unique_edges[i] for i in train_idx]\n",
        "        val_edges = [unique_edges[i] for i in val_idx]\n",
        "\n",
        "        # Convert to numpy arrays first\n",
        "        train_edge_index = np.array([[edge[0], edge[1]] for edge in train_edges]).T\n",
        "        train_edge_attr = np.array([edge_attr[edge_to_idx[edge]] for edge in train_edges])\n",
        "\n",
        "        val_edge_index = np.array([[edge[0], edge[1]] for edge in val_edges]).T\n",
        "        val_edge_attr = np.array([edge_attr[edge_to_idx[edge]] for edge in val_edges])\n",
        "\n",
        "        # Convert to tensors\n",
        "        train_edge_index = torch.from_numpy(train_edge_index).to(device)\n",
        "        train_edge_attr = torch.from_numpy(train_edge_attr).float().to(device)\n",
        "        val_edge_index = torch.from_numpy(val_edge_index).to(device)\n",
        "        val_edge_attr = torch.from_numpy(val_edge_attr).float().to(device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        early_stopping_counter = 0\n",
        "        train_losses = []\n",
        "        val_metrics = {'auc': [], 'ap': [], 'loss': []}\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Training\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            z, edge_features = model(data.x, train_edge_index, train_edge_attr)\n",
        "            pos_out = model.decode(z, edge_features, train_edge_index)\n",
        "\n",
        "            # Generate negative samples\n",
        "            neg_edge_index = negative_sampling(\n",
        "                train_edge_index,\n",
        "                num_nodes=data.num_nodes,\n",
        "                num_neg_samples=train_edge_index.size(1)\n",
        "            )\n",
        "\n",
        "            neg_out = model.decode(z, edge_features, neg_edge_index)\n",
        "            loss = bce_with_logits_loss(pos_out, neg_out)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                z, edge_features = model(data.x, val_edge_index, val_edge_attr)\n",
        "                pos_out = model.decode(z, edge_features, val_edge_index)\n",
        "\n",
        "                neg_edge_index = negative_sampling(\n",
        "                    val_edge_index,\n",
        "                    num_nodes=data.num_nodes,\n",
        "                    num_neg_samples=val_edge_index.size(1)\n",
        "                )\n",
        "\n",
        "                neg_out = model.decode(z, edge_features, neg_edge_index)\n",
        "                val_loss = bce_with_logits_loss(pos_out, neg_out)\n",
        "\n",
        "                # Compute metrics\n",
        "                pred = torch.cat([pos_out, neg_out]).cpu().numpy()\n",
        "                true = torch.cat([\n",
        "                    torch.ones(pos_out.size(0)),\n",
        "                    torch.zeros(neg_out.size(0))\n",
        "                ]).numpy()\n",
        "\n",
        "                auc = roc_auc_score(true, pred)\n",
        "                ap = average_precision_score(true, pred)\n",
        "\n",
        "                val_metrics['auc'].append(auc)\n",
        "                val_metrics['ap'].append(ap)\n",
        "                val_metrics['loss'].append(val_loss.item())\n",
        "\n",
        "                if (epoch + 1) % 10 == 0:\n",
        "                    print(f\"Epoch {epoch + 1}: Train Loss = {loss:.4f}, \"\n",
        "                          f\"Val Loss = {val_loss:.4f}, AUC = {auc:.4f}, AP = {ap:.4f}\")\n",
        "\n",
        "                scheduler.step(val_loss)\n",
        "\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    early_stopping_counter = 0\n",
        "                else:\n",
        "                    early_stopping_counter += 1\n",
        "\n",
        "                if early_stopping_counter >= 20:\n",
        "                    print(\"Early stopping triggered\")\n",
        "                    break\n",
        "\n",
        "        fold_results = {\n",
        "            'fold': fold + 1,\n",
        "            'train_losses': train_losses,\n",
        "            'val_metrics': val_metrics,\n",
        "            'final_auc': auc,\n",
        "            'final_ap': ap\n",
        "        }\n",
        "        all_results.append(fold_results)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def visualize_results(results, network_data, save_path='qkd_results'):\n",
        "    \"\"\"Create comprehensive visualizations and analysis\"\"\"\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    save_path = f\"{save_path}_{timestamp}\"\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # Find the minimum length across all result arrays\n",
        "    min_epochs = min(len(result['train_losses']) for result in results)\n",
        "\n",
        "    # Truncate all arrays to the minimum length\n",
        "    truncated_results = []\n",
        "    for result in results:\n",
        "        truncated_result = {\n",
        "            'train_losses': result['train_losses'][:min_epochs],\n",
        "            'val_metrics': {\n",
        "                'auc': result['val_metrics']['auc'][:min_epochs],\n",
        "                'ap': result['val_metrics']['ap'][:min_epochs],\n",
        "                'loss': result['val_metrics']['loss'][:min_epochs]\n",
        "            },\n",
        "            'final_auc': result['final_auc'],\n",
        "            'final_ap': result['final_ap']\n",
        "        }\n",
        "        truncated_results.append(truncated_result)\n",
        "\n",
        "    # Training Metrics\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Plot training losses\n",
        "    plt.subplot(2, 2, 1)\n",
        "    for result in truncated_results:\n",
        "        plt.plot(result['train_losses'], alpha=0.3)\n",
        "    mean_train_loss = np.mean([r['train_losses'] for r in truncated_results], axis=0)\n",
        "    plt.plot(mean_train_loss, 'r-', label='Mean')\n",
        "    plt.title('Training Loss Evolution')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot validation AUC\n",
        "    plt.subplot(2, 2, 2)\n",
        "    for result in truncated_results:\n",
        "        plt.plot(result['val_metrics']['auc'], alpha=0.3)\n",
        "    mean_val_auc = np.mean([r['val_metrics']['auc'] for r in truncated_results], axis=0)\n",
        "    plt.plot(mean_val_auc, 'r-', label='Mean')\n",
        "    plt.title('Validation AUC Evolution')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.legend()\n",
        "\n",
        "    # Key Rate vs Distance Analysis\n",
        "    distances = network_data.edge_attr[:, 2].cpu().numpy()\n",
        "    key_rates = network_data.edge_attr[:, 0].cpu().numpy()\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.scatter(distances, key_rates, alpha=0.5)\n",
        "    plt.xlabel('Distance (km)')\n",
        "    plt.ylabel('Key Rate (bits/s)')\n",
        "    plt.yscale('log')\n",
        "    plt.title('Key Rate vs Distance')\n",
        "\n",
        "    x_fit = np.linspace(min(distances), max(distances), 100)\n",
        "    y_fit = np.exp(-0.2 * x_fit)\n",
        "    plt.plot(x_fit, y_fit * max(key_rates), 'r--', label='Theoretical')\n",
        "    plt.legend()\n",
        "\n",
        "    # QBER Distribution\n",
        "    plt.subplot(2, 2, 4)\n",
        "    qber_values = network_data.edge_attr[:, 1].cpu().numpy()\n",
        "    sns.histplot(qber_values, bins=20)\n",
        "    plt.xlabel('QBER')\n",
        "    plt.ylabel('Count')\n",
        "    plt.title('QBER Distribution')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{save_path}/training_metrics.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Performance Report\n",
        "    report = {\n",
        "        'network_stats': {\n",
        "            'num_nodes': int(network_data.num_nodes),\n",
        "            'num_edges': int(len(key_rates)),\n",
        "            'avg_degree': float(2 * len(key_rates) / network_data.num_nodes),\n",
        "            'avg_key_rate': float(np.mean(key_rates)),\n",
        "            'avg_qber': float(np.mean(qber_values)),\n",
        "            'max_distance': float(np.max(distances))\n",
        "        },\n",
        "        'model_performance': {\n",
        "            'final_metrics': {\n",
        "                'auc_mean': float(np.mean([r['final_auc'] for r in results])),\n",
        "                'auc_std': float(np.std([r['final_auc'] for r in results])),\n",
        "                'ap_mean': float(np.mean([r['final_ap'] for r in results])),\n",
        "                'ap_std': float(np.std([r['final_ap'] for r in results]))\n",
        "            },\n",
        "            'convergence': {\n",
        "                'final_train_loss_mean': float(np.mean([r['train_losses'][-1] for r in truncated_results])),\n",
        "                'best_epoch_mean': float(np.mean([np.argmin(r['val_metrics']['loss']) for r in truncated_results]))\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(f\"{save_path}/performance_report.json\", 'w') as f:\n",
        "        json.dump(report, f, indent=4)\n",
        "\n",
        "    return report\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Generate network\n",
        "    print(\"Generating QKD network...\")\n",
        "    network = AdvancedQKDNetwork(num_nodes=50)\n",
        "    data = network.generate_graph_data()\n",
        "\n",
        "    # Create and train model\n",
        "    print(\"Creating and training model...\")\n",
        "    model = AdvancedQKDLinkPredictor(\n",
        "        in_channels=data.x.size(1),\n",
        "        edge_attr_channels=data.edge_attr.size(1)\n",
        "    )\n",
        "\n",
        "    # Train and evaluate\n",
        "    results = train_and_evaluate(model, data)\n",
        "\n",
        "    # Generate visualizations and analysis\n",
        "    print(\"Generating visualizations and analysis...\")\n",
        "    save_path = 'qkd_results'\n",
        "    performance_report = visualize_results(results, data, save_path)\n",
        "\n",
        "    print(f\"\\nAnalysis complete. Results saved in: {save_path}\")\n",
        "\n",
        "    # Print summary statistics\n",
        "    print(\"\\nSummary Statistics:\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.edge_index.size(1) // 2}\")\n",
        "    print(f\"Average degree: {data.edge_index.size(1) / data.num_nodes:.2f}\")\n",
        "    print(f\"Average key rate: {performance_report['network_stats']['avg_key_rate']:.2e} bits/s\")\n",
        "    print(f\"Average QBER: {performance_report['network_stats']['avg_qber']:.3f}\")\n",
        "    print(f\"Model AUC: {performance_report['model_performance']['final_metrics']['auc_mean']:.3f} ± \"\n",
        "          f\"{performance_report['model_performance']['final_metrics']['auc_std']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjvkAHvgnBnX",
        "outputId": "c9455c26-7bd8-42c7-88ef-3da8f063fe3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating QKD network...\n",
            "Creating and training model...\n",
            "Using device: cpu\n",
            "\n",
            "Fold 1/5\n",
            "Epoch 10: Train Loss = 1.2926, Val Loss = 1.3279, AUC = 0.6575, AP = 0.6474\n",
            "Epoch 20: Train Loss = 1.0823, Val Loss = 1.1905, AUC = 0.7620, AP = 0.7594\n",
            "Epoch 30: Train Loss = 0.9176, Val Loss = 1.1153, AUC = 0.7827, AP = 0.7259\n",
            "Epoch 40: Train Loss = 0.8326, Val Loss = 1.1891, AUC = 0.7637, AP = 0.7288\n",
            "Epoch 50: Train Loss = 0.7037, Val Loss = 1.1466, AUC = 0.7785, AP = 0.7305\n",
            "Epoch 60: Train Loss = 0.7188, Val Loss = 1.0975, AUC = 0.7993, AP = 0.7599\n",
            "Epoch 70: Train Loss = 0.7263, Val Loss = 1.1522, AUC = 0.7759, AP = 0.7398\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 2/5\n",
            "Epoch 10: Train Loss = 0.7056, Val Loss = 1.1737, AUC = 0.7843, AP = 0.7281\n",
            "Epoch 20: Train Loss = 0.6729, Val Loss = 1.1560, AUC = 0.7887, AP = 0.7383\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 3/5\n",
            "Epoch 10: Train Loss = 0.7089, Val Loss = 1.0001, AUC = 0.8456, AP = 0.8120\n",
            "Epoch 20: Train Loss = 0.5909, Val Loss = 1.2361, AUC = 0.7967, AP = 0.7647\n",
            "Epoch 30: Train Loss = 0.6358, Val Loss = 1.2128, AUC = 0.8136, AP = 0.8064\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 4/5\n",
            "Epoch 10: Train Loss = 0.6107, Val Loss = 1.1168, AUC = 0.8046, AP = 0.7562\n",
            "Epoch 20: Train Loss = 0.6073, Val Loss = 1.0140, AUC = 0.8374, AP = 0.7942\n",
            "Epoch 30: Train Loss = 0.6045, Val Loss = 0.9666, AUC = 0.8478, AP = 0.7913\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 5/5\n",
            "Epoch 10: Train Loss = 0.7698, Val Loss = 0.9740, AUC = 0.8540, AP = 0.8160\n",
            "Epoch 20: Train Loss = 0.6193, Val Loss = 0.9559, AUC = 0.8439, AP = 0.7824\n",
            "Epoch 30: Train Loss = 0.6569, Val Loss = 1.0142, AUC = 0.8289, AP = 0.7489\n",
            "Epoch 40: Train Loss = 0.6152, Val Loss = 0.8920, AUC = 0.8526, AP = 0.7886\n",
            "Early stopping triggered\n",
            "Generating visualizations and analysis...\n",
            "\n",
            "Analysis complete. Results saved in: qkd_results\n",
            "\n",
            "Summary Statistics:\n",
            "Number of nodes: 50\n",
            "Number of edges: 718\n",
            "Average degree: 28.72\n",
            "Average key rate: 1.04e+03 bits/s\n",
            "Average QBER: 0.061\n",
            "Model AUC: 0.814 ± 0.025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import torch\n",
        "# import torch_geometric\n",
        "# from torch_geometric.data import Data\n",
        "# from torch_geometric.nn import GATv2Conv, TransformerConv\n",
        "# from torch_geometric.utils import to_undirected, negative_sampling\n",
        "# import networkx as nx\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "# from scipy.constants import h, c\n",
        "# from sklearn.model_selection import KFold\n",
        "# import json\n",
        "# from datetime import datetime\n",
        "# import os\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# def bce_with_logits_loss(pos_out, neg_out):\n",
        "#     \"\"\"Custom BCE loss for link prediction\"\"\"\n",
        "#     pos_loss = F.binary_cross_entropy_with_logits(\n",
        "#         pos_out, torch.ones_like(pos_out)\n",
        "#     )\n",
        "#     neg_loss = F.binary_cross_entropy_with_logits(\n",
        "#         neg_out, torch.zeros_like(neg_out)\n",
        "#     )\n",
        "#     return pos_loss + neg_loss\n",
        "\n",
        "# def to_networkx(data):\n",
        "#     \"\"\"Convert PyG data to NetworkX graph\"\"\"\n",
        "#     G = nx.Graph()\n",
        "#     edge_index = data.edge_index.cpu().numpy()\n",
        "#     for i in range(edge_index.shape[1]):\n",
        "#         G.add_edge(edge_index[0, i], edge_index[1, i])\n",
        "#     return G\n",
        "\n",
        "# class AdvancedQuantumChannelSimulator:\n",
        "#     def __init__(self, distance, wavelength=1550e-9, fiber_loss=0.2,\n",
        "#                  detector_efficiency=0.1, dark_count_rate=1e-6,\n",
        "#                  atmospheric_visibility=None):\n",
        "#         self.distance = distance\n",
        "#         self.wavelength = wavelength\n",
        "#         self.fiber_loss = fiber_loss\n",
        "#         self.detector_efficiency = detector_efficiency\n",
        "#         self.dark_count_rate = dark_count_rate\n",
        "#         self.atmospheric_visibility = atmospheric_visibility\n",
        "#         self.photon_energy = h * c / wavelength\n",
        "\n",
        "#     def calculate_channel_loss(self):\n",
        "#         fiber_loss_db = self.fiber_loss * self.distance\n",
        "#         fiber_transmission = 10 ** (-fiber_loss_db/10)\n",
        "\n",
        "#         if self.atmospheric_visibility:\n",
        "#             beam_divergence = 1.22 * self.wavelength / 0.1\n",
        "#             geometric_loss = (0.1 / (beam_divergence * self.distance)) ** 2\n",
        "#             atmospheric_loss = np.exp(-3.91 * self.distance / self.atmospheric_visibility)\n",
        "#             total_transmission = fiber_transmission * geometric_loss * atmospheric_loss\n",
        "#         else:\n",
        "#             total_transmission = fiber_transmission\n",
        "\n",
        "#         return total_transmission\n",
        "\n",
        "#     def simulate_bb84_protocol(self, num_pulses=10000, mean_photon_number=0.1):\n",
        "#         channel_transmission = self.calculate_channel_loss()\n",
        "#         received_photons = np.random.poisson(\n",
        "#             mean_photon_number * channel_transmission * self.detector_efficiency,\n",
        "#             num_pulses\n",
        "#         )\n",
        "#         dark_counts = np.random.poisson(self.dark_count_rate, num_pulses)\n",
        "#         total_counts = received_photons + dark_counts\n",
        "#         basis_matches = np.random.choice([0, 1], num_pulses, p=[0.5, 0.5])\n",
        "#         qber = 0.5 * (1 - np.exp(-2 * self.distance / 100))\n",
        "#         errors = np.random.choice([0, 1], num_pulses, p=[1-qber, qber])\n",
        "#         matched_pulses = total_counts * basis_matches\n",
        "#         raw_key_rate = np.sum(matched_pulses) / num_pulses\n",
        "#         final_key_rate = raw_key_rate * (1 - 2 * h2(qber))\n",
        "\n",
        "#         return {\n",
        "#             'qber': qber,\n",
        "#             'raw_key_rate': raw_key_rate,\n",
        "#             'final_key_rate': final_key_rate,\n",
        "#             'channel_loss_db': -10 * np.log10(channel_transmission),\n",
        "#             'dark_count_probability': np.mean(dark_counts > 0)\n",
        "#         }\n",
        "\n",
        "# def h2(x):\n",
        "#     \"\"\"Binary entropy function\"\"\"\n",
        "#     return -x * np.log2(x) - (1-x) * np.log2(1-x) if 0 < x < 1 else 0\n",
        "\n",
        "# class AdvancedQKDNetwork:\n",
        "#     def __init__(self, num_nodes=20):\n",
        "#         self.num_nodes = num_nodes\n",
        "#         self.positions = self._generate_realistic_topology()\n",
        "\n",
        "#     def _generate_realistic_topology(self):\n",
        "#         centers = np.random.multivariate_normal(\n",
        "#             mean=[0, 0],\n",
        "#             cov=[[100, 0], [0, 100]],\n",
        "#             size=3\n",
        "#         )\n",
        "\n",
        "#         positions = []\n",
        "#         for _ in range(self.num_nodes):\n",
        "#             center = centers[np.random.randint(0, 3)]\n",
        "#             pos = center + np.random.multivariate_normal(\n",
        "#                 mean=[0, 0],\n",
        "#                 cov=[[10, 0], [0, 10]]\n",
        "#             )\n",
        "#             positions.append(pos)\n",
        "\n",
        "#         return np.array(positions)\n",
        "\n",
        "#     def generate_graph_data(self):\n",
        "#         distances = np.zeros((self.num_nodes, self.num_nodes))\n",
        "#         for i in range(self.num_nodes):\n",
        "#             for j in range(i + 1, self.num_nodes):\n",
        "#                 distances[i, j] = distances[j, i] = np.linalg.norm(\n",
        "#                     self.positions[i] - self.positions[j]\n",
        "#                 )\n",
        "\n",
        "#         edges = []\n",
        "#         edge_attrs = []\n",
        "\n",
        "#         for i in range(self.num_nodes):\n",
        "#             for j in range(i + 1, self.num_nodes):\n",
        "#                 if distances[i, j] < 100:\n",
        "#                     simulator = AdvancedQuantumChannelSimulator(\n",
        "#                         distance=distances[i, j],\n",
        "#                         atmospheric_visibility=20000 if np.random.random() < 0.2 else None\n",
        "#                     )\n",
        "#                     results = simulator.simulate_bb84_protocol()\n",
        "\n",
        "#                     if results['final_key_rate'] > 0:\n",
        "#                         edges.append([i, j])\n",
        "#                         edge_attrs.append([\n",
        "#                             results['final_key_rate'],\n",
        "#                             results['qber'],\n",
        "#                             distances[i, j],\n",
        "#                             results['channel_loss_db'],\n",
        "#                             results['dark_count_probability']\n",
        "#                         ])\n",
        "\n",
        "#         edge_index = torch.tensor(edges).t().contiguous()\n",
        "#         edge_attr = torch.tensor(edge_attrs, dtype=torch.float)\n",
        "\n",
        "#         G = nx.Graph()\n",
        "#         G.add_edges_from(edges)\n",
        "\n",
        "#         node_features = []\n",
        "#         for i in range(self.num_nodes):\n",
        "#             features = [\n",
        "#                 self.positions[i, 0],\n",
        "#                 self.positions[i, 1],\n",
        "#                 G.degree(i) if i in G else 0,\n",
        "#                 nx.betweenness_centrality(G).get(i, 0) if i in G else 0\n",
        "#             ]\n",
        "#             node_features.append(features)\n",
        "\n",
        "#         return Data(\n",
        "#             x=torch.tensor(node_features, dtype=torch.float),\n",
        "#             edge_index=to_undirected(edge_index),\n",
        "#             edge_attr=edge_attr,\n",
        "#             pos=torch.tensor(self.positions, dtype=torch.float)\n",
        "#         )\n",
        "\n",
        "# # Main execution\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Set random seeds for reproducibility\n",
        "#     torch.manual_seed(42)\n",
        "#     np.random.seed(42)\n",
        "\n",
        "#     # Generate network\n",
        "#     print(\"Generating QKD network...\")\n",
        "#     network = AdvancedQKDNetwork(num_nodes=20)\n",
        "#     data = network.generate_graph_data()\n",
        "\n",
        "#     # Create output directory\n",
        "#     save_path = 'qkd_results'\n",
        "#     os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "#     # Visualize network topology\n",
        "#     plt.figure(figsize=(10, 8))\n",
        "#     pos = {i: data.pos[i].numpy() for i in range(data.num_nodes)}\n",
        "#     G = to_networkx(data)\n",
        "#     nx.draw(G, pos, node_color='lightblue',\n",
        "#             with_labels=True, node_size=500,\n",
        "#             font_size=10, font_weight='bold')\n",
        "#     plt.savefig(f\"{save_path}/network_topology.png\")\n",
        "#     plt.close()\n",
        "\n",
        "#     print(f\"Analysis complete. Results saved in: {save_path}\")\n",
        "\n",
        "#     # Print basic network statistics\n",
        "#     print(\"\\nNetwork Statistics:\")\n",
        "#     print(f\"Number of nodes: {data.num_nodes}\")\n",
        "#     print(f\"Number of edges: {data.edge_index.size(1) // 2}\")  # Divide by 2 for undirected\n",
        "#     print(f\"Average degree: {data.edge_index.size(1) / data.num_nodes:.2f}\")"
      ],
      "metadata": {
        "id": "YhmPunQynGdJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}